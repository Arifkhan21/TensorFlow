{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge    totalRooms  totalBedrooms    population  \\\n",
       "count      20640.000000  20640.000000   20640.000000  20640.000000   \n",
       "mean          28.639486   2635.763081     537.898014   1425.476744   \n",
       "std           12.585558   2181.615252     421.247906   1132.462122   \n",
       "min            1.000000      2.000000       1.000000      3.000000   \n",
       "25%           18.000000   1447.750000     295.000000    787.000000   \n",
       "50%           29.000000   2127.000000     435.000000   1166.000000   \n",
       "75%           37.000000   3148.000000     647.000000   1725.000000   \n",
       "max           52.000000  39320.000000    6445.000000  35682.000000   \n",
       "\n",
       "         households  medianIncome  medianHouseValue  \n",
       "count  20640.000000  20640.000000      20640.000000  \n",
       "mean     499.539680      3.870671     206855.816909  \n",
       "std      382.329753      1.899822     115395.615874  \n",
       "min        1.000000      0.499900      14999.000000  \n",
       "25%      280.000000      2.563400     119600.000000  \n",
       "50%      409.000000      3.534800     179700.000000  \n",
       "75%      605.000000      4.743250     264725.000000  \n",
       "max     6082.000000     15.000100     500001.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = df.drop(['medianHouseValue'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data =df['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,test_size = 0.3,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14448, 6)\n",
      "(14448,)\n",
      "(6192, 6)\n",
      "(6192,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =pd.DataFrame(data=scaler.transform(x_train),columns=x_train.columns,index=x_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =pd.DataFrame(data=scaler.transform(x_test),columns=x_train.columns,index=x_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 88 from C header, got 96 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=x_train,y=y_train,\n",
    "                                                                batch_size = 10,num_epochs = 1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprvzmuahh\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': 600, '_is_chief': True, '_protocol': None, '_master': '', '_save_checkpoints_steps': None, '_train_distribute': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f023fda64a8>, '_eval_distribute': None, '_task_type': 'worker', '_evaluation_master': '', '_tf_random_seed': None, '_service': None, '_device_fn': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_model_dir': '/tmp/tmprvzmuahh', '_keep_checkpoint_max': 5, '_task_id': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],\n",
    "                                  feature_columns=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmprvzmuahh/model.ckpt.\n",
      "INFO:tensorflow:loss = 202716610000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 390.414\n",
      "INFO:tensorflow:loss = 637984050000.0, step = 101 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.588\n",
      "INFO:tensorflow:loss = 366370130000.0, step = 201 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.439\n",
      "INFO:tensorflow:loss = 413600380000.0, step = 301 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.525\n",
      "INFO:tensorflow:loss = 198703450000.0, step = 401 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.338\n",
      "INFO:tensorflow:loss = 246285320000.0, step = 501 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.5\n",
      "INFO:tensorflow:loss = 300228180000.0, step = 601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.334\n",
      "INFO:tensorflow:loss = 213501670000.0, step = 701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.836\n",
      "INFO:tensorflow:loss = 252251720000.0, step = 801 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.38\n",
      "INFO:tensorflow:loss = 505611600000.0, step = 901 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.968\n",
      "INFO:tensorflow:loss = 187479490000.0, step = 1001 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.318\n",
      "INFO:tensorflow:loss = 143192670000.0, step = 1101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.698\n",
      "INFO:tensorflow:loss = 119201000000.0, step = 1201 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.779\n",
      "INFO:tensorflow:loss = 53687120000.0, step = 1301 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.709\n",
      "INFO:tensorflow:loss = 37643727000.0, step = 1401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.178\n",
      "INFO:tensorflow:loss = 86163510000.0, step = 1501 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.131\n",
      "INFO:tensorflow:loss = 40732090000.0, step = 1601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.786\n",
      "INFO:tensorflow:loss = 75216404000.0, step = 1701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.441\n",
      "INFO:tensorflow:loss = 99919970000.0, step = 1801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.969\n",
      "INFO:tensorflow:loss = 87489560000.0, step = 1901 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.75\n",
      "INFO:tensorflow:loss = 99825500000.0, step = 2001 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.881\n",
      "INFO:tensorflow:loss = 101975860000.0, step = 2101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.164\n",
      "INFO:tensorflow:loss = 177495930000.0, step = 2201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.128\n",
      "INFO:tensorflow:loss = 157461890000.0, step = 2301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.298\n",
      "INFO:tensorflow:loss = 29525203000.0, step = 2401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.171\n",
      "INFO:tensorflow:loss = 45539467000.0, step = 2501 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.891\n",
      "INFO:tensorflow:loss = 234127300000.0, step = 2601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.471\n",
      "INFO:tensorflow:loss = 120957034000.0, step = 2701 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.209\n",
      "INFO:tensorflow:loss = 130308540000.0, step = 2801 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.753\n",
      "INFO:tensorflow:loss = 99302040000.0, step = 2901 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.184\n",
      "INFO:tensorflow:loss = 95189740000.0, step = 3001 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.009\n",
      "INFO:tensorflow:loss = 172360070000.0, step = 3101 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.682\n",
      "INFO:tensorflow:loss = 77267060000.0, step = 3201 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.204\n",
      "INFO:tensorflow:loss = 215012130000.0, step = 3301 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.845\n",
      "INFO:tensorflow:loss = 99418780000.0, step = 3401 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.172\n",
      "INFO:tensorflow:loss = 174885490000.0, step = 3501 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.928\n",
      "INFO:tensorflow:loss = 42294770000.0, step = 3601 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.156\n",
      "INFO:tensorflow:loss = 71637430000.0, step = 3701 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.007\n",
      "INFO:tensorflow:loss = 152231020000.0, step = 3801 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.327\n",
      "INFO:tensorflow:loss = 96741760000.0, step = 3901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.525\n",
      "INFO:tensorflow:loss = 48303360000.0, step = 4001 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.155\n",
      "INFO:tensorflow:loss = 66382045000.0, step = 4101 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.939\n",
      "INFO:tensorflow:loss = 116112190000.0, step = 4201 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.485\n",
      "INFO:tensorflow:loss = 45021975000.0, step = 4301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.543\n",
      "INFO:tensorflow:loss = 107794160000.0, step = 4401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.693\n",
      "INFO:tensorflow:loss = 125102150000.0, step = 4501 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.742\n",
      "INFO:tensorflow:loss = 249641580000.0, step = 4601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.744\n",
      "INFO:tensorflow:loss = 70698000000.0, step = 4701 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.646\n",
      "INFO:tensorflow:loss = 111953870000.0, step = 4801 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.288\n",
      "INFO:tensorflow:loss = 157604000000.0, step = 4901 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.42\n",
      "INFO:tensorflow:loss = 45377315000.0, step = 5001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.265\n",
      "INFO:tensorflow:loss = 43473084000.0, step = 5101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.046\n",
      "INFO:tensorflow:loss = 40531255000.0, step = 5201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.722\n",
      "INFO:tensorflow:loss = 55883735000.0, step = 5301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.667\n",
      "INFO:tensorflow:loss = 162953580000.0, step = 5401 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.031\n",
      "INFO:tensorflow:loss = 119026246000.0, step = 5501 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.38\n",
      "INFO:tensorflow:loss = 138565200000.0, step = 5601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.95\n",
      "INFO:tensorflow:loss = 122986004000.0, step = 5701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.007\n",
      "INFO:tensorflow:loss = 102123995000.0, step = 5801 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.186\n",
      "INFO:tensorflow:loss = 205138070000.0, step = 5901 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.102\n",
      "INFO:tensorflow:loss = 178814040000.0, step = 6001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.347\n",
      "INFO:tensorflow:loss = 124588050000.0, step = 6101 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.973\n",
      "INFO:tensorflow:loss = 56444527000.0, step = 6201 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.079\n",
      "INFO:tensorflow:loss = 89287810000.0, step = 6301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.518\n",
      "INFO:tensorflow:loss = 126410070000.0, step = 6401 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.381\n",
      "INFO:tensorflow:loss = 123002000000.0, step = 6501 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.334\n",
      "INFO:tensorflow:loss = 63178654000.0, step = 6601 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 153974590000.0, step = 6701 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.153\n",
      "INFO:tensorflow:loss = 103831090000.0, step = 6801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.371\n",
      "INFO:tensorflow:loss = 106609840000.0, step = 6901 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.367\n",
      "INFO:tensorflow:loss = 112963120000.0, step = 7001 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.166\n",
      "INFO:tensorflow:loss = 90382500000.0, step = 7101 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.315\n",
      "INFO:tensorflow:loss = 144745960000.0, step = 7201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.533\n",
      "INFO:tensorflow:loss = 82912730000.0, step = 7301 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.97\n",
      "INFO:tensorflow:loss = 106340246000.0, step = 7401 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.13\n",
      "INFO:tensorflow:loss = 34825290000.0, step = 7501 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.563\n",
      "INFO:tensorflow:loss = 86113330000.0, step = 7601 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.335\n",
      "INFO:tensorflow:loss = 97779200000.0, step = 7701 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.46\n",
      "INFO:tensorflow:loss = 38587687000.0, step = 7801 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.1\n",
      "INFO:tensorflow:loss = 57119326000.0, step = 7901 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.099\n",
      "INFO:tensorflow:loss = 114728640000.0, step = 8001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.097\n",
      "INFO:tensorflow:loss = 42922484000.0, step = 8101 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.239\n",
      "INFO:tensorflow:loss = 83733320000.0, step = 8201 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.852\n",
      "INFO:tensorflow:loss = 113171440000.0, step = 8301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.457\n",
      "INFO:tensorflow:loss = 58952827000.0, step = 8401 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.741\n",
      "INFO:tensorflow:loss = 90163160000.0, step = 8501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.208\n",
      "INFO:tensorflow:loss = 71687774000.0, step = 8601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.827\n",
      "INFO:tensorflow:loss = 47125630000.0, step = 8701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.374\n",
      "INFO:tensorflow:loss = 37502600000.0, step = 8801 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.561\n",
      "INFO:tensorflow:loss = 125125630000.0, step = 8901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.901\n",
      "INFO:tensorflow:loss = 158815570000.0, step = 9001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.406\n",
      "INFO:tensorflow:loss = 164050320000.0, step = 9101 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.361\n",
      "INFO:tensorflow:loss = 98128810000.0, step = 9201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.353\n",
      "INFO:tensorflow:loss = 73269580000.0, step = 9301 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.995\n",
      "INFO:tensorflow:loss = 133313790000.0, step = 9401 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.334\n",
      "INFO:tensorflow:loss = 65466310000.0, step = 9501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.714\n",
      "INFO:tensorflow:loss = 86675870000.0, step = 9601 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.995\n",
      "INFO:tensorflow:loss = 93870520000.0, step = 9701 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.743\n",
      "INFO:tensorflow:loss = 82635210000.0, step = 9801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.868\n",
      "INFO:tensorflow:loss = 58918666000.0, step = 9901 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.072\n",
      "INFO:tensorflow:loss = 119218750000.0, step = 10001 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.366\n",
      "INFO:tensorflow:loss = 47540355000.0, step = 10101 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.36\n",
      "INFO:tensorflow:loss = 196626940000.0, step = 10201 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.132\n",
      "INFO:tensorflow:loss = 104459940000.0, step = 10301 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.882\n",
      "INFO:tensorflow:loss = 67195085000.0, step = 10401 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.905\n",
      "INFO:tensorflow:loss = 102857980000.0, step = 10501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.486\n",
      "INFO:tensorflow:loss = 104247600000.0, step = 10601 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.808\n",
      "INFO:tensorflow:loss = 105466830000.0, step = 10701 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.624\n",
      "INFO:tensorflow:loss = 155238200000.0, step = 10801 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.263\n",
      "INFO:tensorflow:loss = 60392018000.0, step = 10901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.781\n",
      "INFO:tensorflow:loss = 39041390000.0, step = 11001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.712\n",
      "INFO:tensorflow:loss = 118935230000.0, step = 11101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.461\n",
      "INFO:tensorflow:loss = 44243750000.0, step = 11201 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.212\n",
      "INFO:tensorflow:loss = 129362670000.0, step = 11301 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.601\n",
      "INFO:tensorflow:loss = 70774580000.0, step = 11401 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.475\n",
      "INFO:tensorflow:loss = 93014560000.0, step = 11501 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.79\n",
      "INFO:tensorflow:loss = 135774830000.0, step = 11601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.906\n",
      "INFO:tensorflow:loss = 71753610000.0, step = 11701 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.319\n",
      "INFO:tensorflow:loss = 201722040000.0, step = 11801 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.774\n",
      "INFO:tensorflow:loss = 116833030000.0, step = 11901 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.02\n",
      "INFO:tensorflow:loss = 63299215000.0, step = 12001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.134\n",
      "INFO:tensorflow:loss = 99820020000.0, step = 12101 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.459\n",
      "INFO:tensorflow:loss = 217512800000.0, step = 12201 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.138\n",
      "INFO:tensorflow:loss = 75385120000.0, step = 12301 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.203\n",
      "INFO:tensorflow:loss = 106845820000.0, step = 12401 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.649\n",
      "INFO:tensorflow:loss = 129462125000.0, step = 12501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.063\n",
      "INFO:tensorflow:loss = 82716240000.0, step = 12601 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.678\n",
      "INFO:tensorflow:loss = 191960450000.0, step = 12701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.38\n",
      "INFO:tensorflow:loss = 68028920000.0, step = 12801 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.925\n",
      "INFO:tensorflow:loss = 47123866000.0, step = 12901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.53\n",
      "INFO:tensorflow:loss = 170787850000.0, step = 13001 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.818\n",
      "INFO:tensorflow:loss = 92523040000.0, step = 13101 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.245\n",
      "INFO:tensorflow:loss = 70032515000.0, step = 13201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.474\n",
      "INFO:tensorflow:loss = 251671300000.0, step = 13301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.813\n",
      "INFO:tensorflow:loss = 21855193000.0, step = 13401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.912\n",
      "INFO:tensorflow:loss = 53626160000.0, step = 13501 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.144\n",
      "INFO:tensorflow:loss = 79055010000.0, step = 13601 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.883\n",
      "INFO:tensorflow:loss = 51807126000.0, step = 13701 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.138\n",
      "INFO:tensorflow:loss = 159259440000.0, step = 13801 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.172\n",
      "INFO:tensorflow:loss = 119926325000.0, step = 13901 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.302\n",
      "INFO:tensorflow:loss = 121804276000.0, step = 14001 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.808\n",
      "INFO:tensorflow:loss = 33886495000.0, step = 14101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.053\n",
      "INFO:tensorflow:loss = 83900330000.0, step = 14201 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.84\n",
      "INFO:tensorflow:loss = 59390830000.0, step = 14301 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.273\n",
      "INFO:tensorflow:loss = 137841590000.0, step = 14401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.778\n",
      "INFO:tensorflow:loss = 64059023000.0, step = 14501 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 185419580000.0, step = 14601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.782\n",
      "INFO:tensorflow:loss = 130453170000.0, step = 14701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.466\n",
      "INFO:tensorflow:loss = 65635460000.0, step = 14801 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.413\n",
      "INFO:tensorflow:loss = 53810414000.0, step = 14901 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.723\n",
      "INFO:tensorflow:loss = 208018540000.0, step = 15001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.783\n",
      "INFO:tensorflow:loss = 103854810000.0, step = 15101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.581\n",
      "INFO:tensorflow:loss = 117458910000.0, step = 15201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.351\n",
      "INFO:tensorflow:loss = 55215660000.0, step = 15301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.208\n",
      "INFO:tensorflow:loss = 39723700000.0, step = 15401 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.486\n",
      "INFO:tensorflow:loss = 134398580000.0, step = 15501 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.671\n",
      "INFO:tensorflow:loss = 54409523000.0, step = 15601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.014\n",
      "INFO:tensorflow:loss = 89798020000.0, step = 15701 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.142\n",
      "INFO:tensorflow:loss = 123231715000.0, step = 15801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.943\n",
      "INFO:tensorflow:loss = 103937800000.0, step = 15901 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.932\n",
      "INFO:tensorflow:loss = 160348050000.0, step = 16001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.97\n",
      "INFO:tensorflow:loss = 32367985000.0, step = 16101 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.024\n",
      "INFO:tensorflow:loss = 54637445000.0, step = 16201 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.042\n",
      "INFO:tensorflow:loss = 40535077000.0, step = 16301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.751\n",
      "INFO:tensorflow:loss = 141198740000.0, step = 16401 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.586\n",
      "INFO:tensorflow:loss = 93489840000.0, step = 16501 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.306\n",
      "INFO:tensorflow:loss = 177026780000.0, step = 16601 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.07\n",
      "INFO:tensorflow:loss = 74661495000.0, step = 16701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.496\n",
      "INFO:tensorflow:loss = 63280280000.0, step = 16801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.058\n",
      "INFO:tensorflow:loss = 75099095000.0, step = 16901 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.818\n",
      "INFO:tensorflow:loss = 78845430000.0, step = 17001 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.165\n",
      "INFO:tensorflow:loss = 121356080000.0, step = 17101 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.11\n",
      "INFO:tensorflow:loss = 117966635000.0, step = 17201 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.514\n",
      "INFO:tensorflow:loss = 68474280000.0, step = 17301 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.541\n",
      "INFO:tensorflow:loss = 80167230000.0, step = 17401 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.519\n",
      "INFO:tensorflow:loss = 68600560000.0, step = 17501 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.672\n",
      "INFO:tensorflow:loss = 129137670000.0, step = 17601 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.892\n",
      "INFO:tensorflow:loss = 41315496000.0, step = 17701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.626\n",
      "INFO:tensorflow:loss = 18432258000.0, step = 17801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.978\n",
      "INFO:tensorflow:loss = 163984340000.0, step = 17901 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.297\n",
      "INFO:tensorflow:loss = 44430160000.0, step = 18001 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.354\n",
      "INFO:tensorflow:loss = 142416330000.0, step = 18101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.431\n",
      "INFO:tensorflow:loss = 121176605000.0, step = 18201 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.888\n",
      "INFO:tensorflow:loss = 54063260000.0, step = 18301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.312\n",
      "INFO:tensorflow:loss = 132435900000.0, step = 18401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.824\n",
      "INFO:tensorflow:loss = 160558280000.0, step = 18501 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.221\n",
      "INFO:tensorflow:loss = 125750590000.0, step = 18601 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.566\n",
      "INFO:tensorflow:loss = 115362280000.0, step = 18701 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.021\n",
      "INFO:tensorflow:loss = 142940910000.0, step = 18801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.969\n",
      "INFO:tensorflow:loss = 73059220000.0, step = 18901 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.215\n",
      "INFO:tensorflow:loss = 88326590000.0, step = 19001 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.541\n",
      "INFO:tensorflow:loss = 86957515000.0, step = 19101 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.495\n",
      "INFO:tensorflow:loss = 68462120000.0, step = 19201 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.382\n",
      "INFO:tensorflow:loss = 58361340000.0, step = 19301 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.804\n",
      "INFO:tensorflow:loss = 70264870000.0, step = 19401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.523\n",
      "INFO:tensorflow:loss = 101444250000.0, step = 19501 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.118\n",
      "INFO:tensorflow:loss = 54255616000.0, step = 19601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.59\n",
      "INFO:tensorflow:loss = 70954470000.0, step = 19701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.728\n",
      "INFO:tensorflow:loss = 189121180000.0, step = 19801 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.286\n",
      "INFO:tensorflow:loss = 133984535000.0, step = 19901 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.013\n",
      "INFO:tensorflow:loss = 170666050000.0, step = 20001 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.514\n",
      "INFO:tensorflow:loss = 112237320000.0, step = 20101 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.801\n",
      "INFO:tensorflow:loss = 90276910000.0, step = 20201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.049\n",
      "INFO:tensorflow:loss = 79087110000.0, step = 20301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.049\n",
      "INFO:tensorflow:loss = 44259330000.0, step = 20401 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.013\n",
      "INFO:tensorflow:loss = 97464470000.0, step = 20501 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.932\n",
      "INFO:tensorflow:loss = 62274757000.0, step = 20601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.853\n",
      "INFO:tensorflow:loss = 173672200000.0, step = 20701 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.912\n",
      "INFO:tensorflow:loss = 194345660000.0, step = 20801 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.755\n",
      "INFO:tensorflow:loss = 69172870000.0, step = 20901 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.43\n",
      "INFO:tensorflow:loss = 60196840000.0, step = 21001 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.979\n",
      "INFO:tensorflow:loss = 193120960000.0, step = 21101 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.427\n",
      "INFO:tensorflow:loss = 140559190000.0, step = 21201 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.656\n",
      "INFO:tensorflow:loss = 49014473000.0, step = 21301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.599\n",
      "INFO:tensorflow:loss = 98457190000.0, step = 21401 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.069\n",
      "INFO:tensorflow:loss = 104558720000.0, step = 21501 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.592\n",
      "INFO:tensorflow:loss = 170406020000.0, step = 21601 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.111\n",
      "INFO:tensorflow:loss = 27004305000.0, step = 21701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.18\n",
      "INFO:tensorflow:loss = 71566800000.0, step = 21801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 460\n",
      "INFO:tensorflow:loss = 87915560000.0, step = 21901 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.59\n",
      "INFO:tensorflow:loss = 41732633000.0, step = 22001 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.646\n",
      "INFO:tensorflow:loss = 147608830000.0, step = 22101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.4\n",
      "INFO:tensorflow:loss = 192396980000.0, step = 22201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.749\n",
      "INFO:tensorflow:loss = 81012840000.0, step = 22301 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.922\n",
      "INFO:tensorflow:loss = 130092080000.0, step = 22401 (0.217 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 426.887\n",
      "INFO:tensorflow:loss = 65388260000.0, step = 22501 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.665\n",
      "INFO:tensorflow:loss = 117462630000.0, step = 22601 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.121\n",
      "INFO:tensorflow:loss = 38983786000.0, step = 22701 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.63\n",
      "INFO:tensorflow:loss = 226048280000.0, step = 22801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.848\n",
      "INFO:tensorflow:loss = 114428666000.0, step = 22901 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.945\n",
      "INFO:tensorflow:loss = 66342010000.0, step = 23001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.2\n",
      "INFO:tensorflow:loss = 191447140000.0, step = 23101 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.335\n",
      "INFO:tensorflow:loss = 199905180000.0, step = 23201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.701\n",
      "INFO:tensorflow:loss = 84157506000.0, step = 23301 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.506\n",
      "INFO:tensorflow:loss = 51532235000.0, step = 23401 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.197\n",
      "INFO:tensorflow:loss = 49031315000.0, step = 23501 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.157\n",
      "INFO:tensorflow:loss = 41307128000.0, step = 23601 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.2\n",
      "INFO:tensorflow:loss = 84228670000.0, step = 23701 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.672\n",
      "INFO:tensorflow:loss = 59718988000.0, step = 23801 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.568\n",
      "INFO:tensorflow:loss = 71207650000.0, step = 23901 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.404\n",
      "INFO:tensorflow:loss = 136752160000.0, step = 24001 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.182\n",
      "INFO:tensorflow:loss = 69377070000.0, step = 24101 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.408\n",
      "INFO:tensorflow:loss = 57447080000.0, step = 24201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.561\n",
      "INFO:tensorflow:loss = 54396408000.0, step = 24301 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.318\n",
      "INFO:tensorflow:loss = 42010874000.0, step = 24401 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.771\n",
      "INFO:tensorflow:loss = 106526786000.0, step = 24501 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.562\n",
      "INFO:tensorflow:loss = 56193114000.0, step = 24601 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.171\n",
      "INFO:tensorflow:loss = 112634315000.0, step = 24701 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.691\n",
      "INFO:tensorflow:loss = 45291012000.0, step = 24801 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.635\n",
      "INFO:tensorflow:loss = 31636562000.0, step = 24901 (0.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tmprvzmuahh/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 47498453000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7f023fda67b8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(x = x_test,y=y_test\n",
    "                                                        ,shuffle=False\n",
    "                                                        ,batch_size=10,\n",
    "                                                        num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(input_fn=predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmprvzmuahh/model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "preds = list(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in preds:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## making it Root Mean Squared by taking Squared root of the returned value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97003.42313848576"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
